---
echo: true
code-fold: true
monofont: Fira Code Light
execute:
  warning: false
  code-fold: true
---

# Country

In this section I will try to look at the `medium_country` data from a higher level - aggregated per country. I would like to see first an intro to the data, which countries drive the most users and revenue, try to identify a subset on which I can focus the analysis and lastly - try to give an advice to our client by just looking at this level.

The first section is exploring the data - feel free to jump to the more interesting parts:

-   A [look into](#conv-rate-rev-per-transaction) which countries could simultaneously be good and converting traffic and having high revenue per transaction
-   Kind of "thought experiment" on how to gain better marketing traction just by [looking at](#market-penetration) the current situation

## Data exploration

```{r}
#| label: setup
library("here")
library("fs")
library("DT")
library("janitor")
library("scales")
library("tidyverse")

data_dir <- "data"
file_name <- "medium_country.csv"

medium_country_raw <- read_csv(
  path_join(c(here(), data_dir, file_name)),
  skip = 6
) |> 
  clean_names()

n_countries_total <- medium_country_raw$country |> unique() |> length()
```

The source file contains data on `r n_countries_total` countries in total and e.g. looks like this for Croatia

```{r}
#| label: show-example-raw-data
medium_country_raw |> 
  filter(country == "Croatia") |> 
  arrange(desc(revenue)) |> 
  datatable()
```

The data is on country / medium level so I would like to collapse it down to just the country level grouping and compute some additional high-level metrics.

```{r}
#| label: aggregate-to-country-level
by_country <- 
  medium_country_raw |> 
  group_by(country) |> 
  summarise(
    # summable-metrics
    across(
      c(users, new_users, sessions, transactions, revenue),
      sum
    ),
    # take means for the rates, shares, durations
    across(
      c(bounce_rate, pages_session, avg_session_duration, ecommerce_conversion_rate),
      mean
    )
  ) |> 
  ungroup() |> 
  # calculate new columns
  mutate(
    revenue_per_transaction = revenue / transactions,
    new_users_share = new_users / users
  )


by_country |>
  filter(country == "Croatia") |>
  mutate(across(is.numeric, ~ round(.x, 3))) |> 
  datatable(options = list(dom = 't'))
```

## Low volume countries

Are there countries with very very low volume of users, transactions or revenue ?

I would pick `users, transactions, revenue` as most important metrics and look at their quantiles.

```{r}
#| label: important-metrics-quantiles
by_country |> 
  select(users, transactions, revenue) |> 
  map(quantile, probs = seq(0, 1, 0.05))
```

-   about \~20% of the countries have less than \~1000 users
-   in terms of transactions it looks like \~45% of the countries have less than \~100 transactions
-   in terms of revenue taking \~20,000€ as cutoff point would remove \~25% of the countries

Arguably these are random cut-off points that I just picked and make sense to me - such choices are definitely debatable. My goal is to reduce the noise in the data and focus on the bigger players where potential changes in the marketing strategy would make sense (e.g. compared to low volume countries where suggesting changes in the marketing strategy would have limited impact).

Based on this quick checks I am inclined to set some simple rules like

`revenue <= 20,000  or  users <= 1,000  or  transactions <= 100`

I can go back to revise this later if needed, in case there is still lots of noise or conversely i am missing some granularity, as well as look more into the lower revenue countries to see if there is something to be said for them separately. (TODO: link to appendix for this check ?)

The potentially-to-be-removed countries seem to be indeed small countries.

```{r}
#| label: show-low-volume-countries-1
by_country |>
  filter(
    (revenue <= 20000) | (users <= 1000) | (transactions <= 100)
  ) |>
  select(country, users:revenue) |> 
  arrange(desc(revenue)) |> 
  datatable()
```

Doing a qualitative check along this list confirms that these seems to be small and not so interesting countries indeed - either in terms of volume of traffic or very small number of transactions.

How many countries will be removed with this rule ? How much of the revenue do they contribute to ?

```{r}
#| label: show-low-volume-countries-2
by_country |> 
  mutate(
    too_low_volume = {
      (revenue <= 20000) | (users <= 1000) | (transactions <= 100)
    }
  ) |> 
  group_by(too_low_volume) |> 
  summarise(
    n_countries = n(),
    revenue = sum(revenue)
  ) |> 
  ungroup() |> 
  mutate(
    perc_revenue   = round(revenue / sum(revenue), 3),
    perc_countries = round(n_countries / sum(n_countries), 3)
  ) |> 
  datatable(options = list(dom = 't'))
```

I would be removing 104 countries \~43% of the total number but half a percent in terms of revenue. This seems ok to me (for now - perhaps to be revised later).

### Remove low volume countries

```{r}
#| label: remove-low-volume-countries
by_country <- by_country |> 
  filter(
    (revenue > 20000) & (users > 1000) & (transactions > 100)
  )
```

## Revenue map

I'm curious to see how the business of the client looks like more visually. I would like to plot the world in terms of buckets of revenue (split roughly and evenly in 7 buckets) in order to see how the "concentration" looks like.

```{r}
#| label: revenue-map
#| warning: false
#| message: false
#| column: screen
#| out-width: 60%
#| fig-format: svg
library("rworldmap")

# split revenue into buckets
by_country <- 
  by_country |> 
  mutate(revenue_ntile = ntile(revenue, n = 7))

# map
by_country_map <- joinCountryData2Map(
  by_country,
  joinCode = "NAME",
  nameJoinColumn = "country"
)

colours <- RColorBrewer::brewer.pal(11, "BrBG")[c(2:5, 9:10)]

mapCountryData(
  by_country_map,
  nameColumnToPlot = "revenue_ntile",
  numCats = 5,
  colourPalette = colours,
  mapTitle = "Map in terms of revenue buckets"
)
```

-   Western Europe, Russia, Japan, Australia, North Americas and Brazil are top tiers
-   The middle tiers would be China, India, Argentina, Chile, South Africa, Turkey
-   Bottom tiers would be most of North Africa and some of the Middle East

I *expect* the map to look very similar if we plot \# of users, sessions or transactions instead.

One interesting thing to notice here is that the briefing from the client mentions that Argentina is a top market country with 30%+ market shere, however looking at the map it is a tier-2 country.

```{r}
hues::swatch(colours)
```

# Which countries drive the most ?

Next I would like to take a look at the main "drivers" in terms of all the main metrics. I would like to make simple plots where countries would be ordered by their volume with respect to the main metrics.

::: panel-tabset
## Users

```{r}
#| label: most-users-plot
by_country |> 
  slice_max(order_by = users, n = 30) |> 
  mutate(country = fct_reorder(country, users)) |> 
  ggplot(aes(x = users, y = country)) +
  geom_col(fill = "mediumpurple4") +
  scale_x_continuous(labels = comma_format(), expand = c(0, 0.3)) +
  labs(
    title = "Which countries drive the most users ?",
    x = "# Users",
    y = NULL
  ) +
  theme_minimal() +
  theme(plot.title.position = "plot")
```

## New Users

```{r}
#| label: most-new-users-plot
by_country |> 
  slice_max(order_by = new_users, n = 30) |> 
  mutate(country = fct_reorder(country, new_users)) |> 
  ggplot(aes(x = new_users, y = country)) +
  geom_col(fill = "mediumpurple4") +
  scale_x_continuous(labels = comma_format(), expand = c(0, 0.3)) +
  labs(
    title = "Which countries drive the most new users ?",
    x = "# New Users",
    y = NULL
  ) +
  theme_minimal() +
  theme(plot.title.position = "plot")
```

## Transactions

```{r}
#| label: most-transactions-plot
by_country |> 
  slice_max(order_by = transactions, n = 30) |> 
  mutate(country = fct_reorder(country, transactions)) |> 
  ggplot(aes(x = transactions, y = country)) +
  geom_col(fill = "mediumpurple4") +
  scale_x_continuous(labels = comma_format(), expand = c(0, 0.3)) +
  labs(
    title = "Which countries drive the most transactions ?",
    x = "# Transactions",
    y = NULL
  ) +
  theme_minimal() +
  theme(plot.title.position = "plot")
```

## Revenue

```{r}
#| label: most-revenue-plot
by_country |> 
  slice_max(order_by = revenue, n = 30) |> 
  mutate(country = fct_reorder(country, revenue)) |> 
  ggplot(aes(x = revenue, y = country)) +
  geom_col(fill = "mediumpurple4") +
  scale_x_continuous(labels = comma_format(), expand = c(0, 0.3)) +
  labs(
    title = "Which countries drive the most revenue ?",
    x = "€ Revenue",
    y = NULL
  ) +
  theme_minimal() + 
  theme(plot.title.position = "plot")
```
:::

It seems that it is quite similar across the main metrics with the usual top countries driving the most (new) users, transactions and revenue.

```{r}
by_country |> 
  slice_max(order_by = ecommerce_conversion_rate, n = 30) |> 
  mutate(country = fct_reorder(country, ecommerce_conversion_rate)) |> 
  ggplot(aes(x = ecommerce_conversion_rate, y = country)) +
  geom_col(fill = "mediumpurple4") +
  scale_x_continuous(labels = percent_format(), expand = c(0, 0)) +
  labs(
    title = "Which countries drive the most revenue ?",
    x = "€ Revenue",
    y = NULL
  ) +
  theme_minimal() + 
  theme(plot.title.position = "plot")
```

## Conclusions from this part

```{r}
by_country |> 
  filter(country != "(not set)") |> 
  arrange(
    desc(revenue),
    desc(users), 
    desc(ecommerce_conversion_rate),
    desc(transactions),
  ) |> 
  head(12)
```

# Conversion rate vs. revenue per transaction {#conv-rate-rev-per-transaction}

## High

Countries that convert traffic and have high revenue per transaction are very valuable. In case the traffic is low in such a country - then a suggestion could be to scale up marketing and bring in more traffic.

I would take a look at:

-   countries that convert traffic better than half of the countries in the list
-   their revenue per transaction is above the average level

```{r}
#| label: high-conv-rate-valuable-setup
high_conv_rate_and_valuable <- by_country |> 
  filter(country != "(not set)", transactions > 2000) |> 
  mutate(
    diff_to_mean_revenue_per_transaction = {
      as.integer(revenue_per_transaction - mean(revenue_per_transaction))
    },
    ecommerce_conversion_rate = percent_format(accuracy = 0.01,)(ecommerce_conversion_rate),
    revenue_per_transaction = as.integer(revenue_per_transaction),
    # country has better ecomm.conv.rate than 50% of the others
    is_top_converting_country = percent_rank(desc(ecommerce_conversion_rate)) <= 0.5,
    # country has above average revenue per transaction
    is_rev_per_trans_higher_than_avg = diff_to_mean_revenue_per_transaction > 0
  ) |> 
  select(
    country,
    ecommerce_conversion_rate,
    is_top_converting_country,
    revenue_per_transaction,
    diff_to_mean_revenue_per_transaction,
    is_rev_per_trans_higher_than_avg,
    users,
    new_users,
    transactions,
    revenue,
    sessions
  ) |> 
  filter( is_top_converting_country, is_rev_per_trans_higher_than_avg ) |> 
  arrange(desc(ecommerce_conversion_rate), desc(revenue_per_transaction))

datatable(high_conv_rate_and_valuable)
```

## Conclusion for this part {#conv-rate-rev-per-transaction-conclusions}

The above list of countries is an interesting subset of all the countries in terms of good converting and high revenue traffic. Taking New Zealand and Japan as example:

-   Japan is one of the 3 countries in this list with conv.rate higher than 1% while also having revenue per transaction that is 91€ higher than the average
-   New Zealand is slightly below with conv.rate of 0.94% but it's revenue per transaction is 230€ higher than the average

It would make sense to invest in marketing in these countries as the traffic is very valuable and very likely to convert.

```{r}
#| label: high-conv-rate-valuable-candidates-save
high_conv_rate_and_valuable_candidates <- high_conv_rate_and_valuable |> 
  select(country) |>
  mutate(good_conversion_and_high_value = T)

filename <- "high_conv_rate_and_valuable_candidates.csv"

high_conv_rate_and_valuable_candidates |> 
  write_csv(path_join(c(here(), data_dir, filename)))
```

## Low

A small side note could be to inspect the countries with the lowest conv.rate that do bring lots of users to the website. Perhaps by investing some money into improving the quality of service in these countries could bring lots of gain due to the potentially gaining many new paying customers that are currently for some reason not trusting/buying the service.

```{r}

low_conv_rate_high_traffic <- by_country |> 
  filter(country != "(not set)", transactions > 2000) |> 
  mutate(
    diff_to_mean_revenue_per_transaction = {
      as.integer(revenue_per_transaction - mean(revenue_per_transaction))
    },
    ecommerce_conversion_rate = percent_format(accuracy = 0.01,)(ecommerce_conversion_rate),
    revenue_per_transaction = as.integer(revenue_per_transaction),
    # country has better ecomm.conv.rate than 50% of the others
    is_bottom_converting_country = percent_rank(desc(ecommerce_conversion_rate)) >= 0.75,
    # country has above average revenue per transaction
    is_rev_per_trans_higher_than_avg = diff_to_mean_revenue_per_transaction > 0
  ) |> 
  select(
    country,
    ecommerce_conversion_rate,
    is_bottom_converting_country,
    revenue_per_transaction,
    diff_to_mean_revenue_per_transaction,
    is_rev_per_trans_higher_than_avg,
    users,
    new_users,
    transactions,
    revenue,
    sessions
  ) |> 
  filter( is_bottom_converting_country ) |> 
  arrange(desc(users)) |> 
  head(3)

datatable(low_conv_rate_high_traffic)
```

Take for example Lithuania - it brings a lot of new users to the website yet it converts / transacts very badly - this could be indication of some problem with the service ? It could be worth exploring because of the potential for gaining new transacting customers easily.

# Market penetration {#market-penetration}

I would like to try out the following:

-   we have the data on how many transactions from a country the client had in 2022
    -   let's assume these are all unique customers i.e. there are no customers with multiple transactions in a country (see also the callout below)
-   we can get the data on countries population as well as proportion of population from each country that participates in tourism. these could be our \~ theoretical upper bound on the number of customers from a country i.e. imagining that every person from a country has purchased with the client - then we should see this number of customers coming from a certain country
-   the ratio of the first point to the second - would give us a view on "market penetration" - in the sense that we can say `1 in N` people from a country have purchased with the client in 2022
-   to tie this together - comparing these ratios between *comparable* countries could give us an idea where we could boost our marketing efforts and increase the market presence

::: {.callout-important appearance="simple"}
For the sake of this "thought experiment" let's assume these are all unique individual customers i.e. there are no users with multiple transactions in the data. This is a **huge assumption** but since we do not have the data on unique \# customers that purchased something with our client - this has to do.

We could either assume some transaction factor for each users e.g. a user makes 2 transactions per year on average - and then scale the \# transactions down. Or we could try to get the correct data on the unique \# customers for each country.
:::

Luckily it was relatively easy to find the extra data on country population and participation in tourism e.g. from the Eurostat website - [Proportion of population that participated in tourism](https://ec.europa.eu/eurostat/statistics-explained/index.php?title=Tourism_statistics).

More concretely i need to combine 3 datasets and calculate the additional metrics:

-   `customers := transactions` (the big assumption)
-   `customers share := customers / tourists` (\~ market penetration)
-   `one in N is customer := 100 / customers share` (\~ easier to understand view on the above)

```{r}
#| label: setup-market-penetration
library("openintro")
library("eurostat")

# total population of countries
world_pop <- openintro::world_pop

country_population <-
  world_pop |> 
  as_tibble() |> 
  select(country, year_2020) |> 
  rename(population = year_2020)

# prorortion of population that participates in tourism
country_tourists <- 
  get_eurostat("tour_dem_totot", cache = T) |>
  label_eurostat() |> 
  filter(
    duration == "1 night or over",
    c_dest == "All countries of the world",
    unit == "Number",
    time == ymd(20210101)
  )|> 
  select(geo, values) |>
  rename(country = geo, tourists = values)

# transactions ~ # of customers from country for our client
country_customers <- 
  by_country |> 
  filter(country != "(not set)") |> 
  slice_max(order_by = transactions, n = 30) |> 
  select(country, transactions, revenue, revenue_per_transaction) |> 
  rename(customers = transactions)

# stick it all together
country_penetration <- 
  country_customers |> 
  left_join(country_population, join_by(country)) |> 
  left_join(country_tourists, join_by(country)) |> 
  mutate(
    customers_share = customers / tourists,
    one_in_N_tourists_has_transacted = floor(1 / customers_share),
    customers_share = percent_format(accuracy = 0.001)(customers_share)
  ) |> 
  mutate(across(is.numeric, ~ round(.x , 0))) |> 
  arrange(desc(customers_share))

datatable(country_penetration)
```

Not all countries got matched - the tourism data is only for EU but that would do.

```{r}
#| label: eu-market-penetration
country_penetration |> 
  filter( !is.na(one_in_N_tourists_has_transacted) ) |> 
  select(
    country,
    customers,
    tourists,
    one_in_N_tourists_has_transacted,
    customers_share,
    revenue,
    revenue_per_transaction
  ) |> 
  datatable()
```

The list contains countries that I believe can be considered in pairs - where one of the countries is ranked higher in this view of market penetration and the other one lower. Given that they are similar (which is the assumption in this part but needs to be checked with the client if that also makes sense from their business and marketing perspective) - the suggestion would be to use the higher-ranked country, check if there are some marketing initiatives that the client has done there but not in the lower-ranked country - then use this as a suggestion to marketing expansion.

For example such pairs could be:

-   Norway \<-\> Sweden
-   Greece \<-\> Portugal
-   Czechia \<-\> Austria
-   Italy \<-\> Spain
-   Belgium \<-\> Netherlands
-   France \<-\> Germany

```{r}
#| label: potential-mkt-scaling-candidates-save
filename <- "potential_mkt_scaling_candidates.csv"

potential_mkt_scaling <- tibble(
  country = c(
    "Sweden",
    "Portugal",
    "Austria",
    "Spain",
    "Netherlands",
    "Germany"
  )
) |> 
  mutate(potential_marketing_scaling = T)
 
write_csv(potential_mkt_scaling, path_join(c(here(), data_dir, filename)))
```

Taking Germany and France as an example - the reasoning would be as following:

-   1 in 962 German people was a customer with our client in 2022
-   1 in 632 French people was a customer with our client in 2022

*Assuming* these 2 are comparable markets, where our client has similar marketing initiatives, efforts, spend etc.

The argument would be - If we could get the same market penetration in Germany as we have in France - for instance by using the same "marketing playbook" the client did in France. Then they could potentially increase their market penetration in Germany from `0.104% -> 0.158%` .

Recalibrating the numbers from Germany with this potential penetration we would get:

```{r}
#| label: germany-potential

# numbers from table above
current_revenue_germany   <- 12906843
current_customers_germany <-    48819
current_revenue_per_customer_germany <- 264

tourists_germany <- 46994591

# the current and "hypothetical" customer share
# the client could achieve
current_customer_share_germany   <- 0.00104
potential_customer_share_germany <- 0.00158

# potential customers if increase happens
potential_customers_germany <- floor(
  potential_customer_share_germany * tourists_germany
)
# potential revenue that follows from above
potential_revenue_germany <- (
  current_revenue_per_customer_germany * potential_customers_germany
)
# extra revenue and uplift in revenue in Germany
c(
  "Increase in Revenue Germany" = comma_format(suffix = "€")(
    potential_revenue_germany - current_revenue_germany
  ),
  "Uplift Revenue Germany" = percent_format(accuracy = 0.01)(
    (potential_revenue_germany - current_revenue_germany) / current_revenue_germany
  )
)
```

The potential absolute increase in revenue would be \~ 6,5 Mil € or a 50% uplift compared to 2022.

However good or attractive these numbers look - they are based on some very big assumptions

-   that \# transactions = \# unique customers
-   that markets are comparable and would respond to the same marketing strategy i.e. that the same playbook would deliver the desired results across countries
    -   N.B. in my opinion this is not a crazy assumption but needs to be definitely discussed and checked with the domain experts and marketing team from our client
-   assuming both assumptions above even hold - then lastly it does not have to follow that the extra new customers would deliver the same average value as the "first" customers i.e. we could be acquiring lower-value-customers in a country (or the first 1000 customers do not spend like the last 1000 customers)
    -   this would mean non-linear increase in revenue when linearly increasing the customer base

In conclusion - we could repeat this kind of line or reasoning with the correct data on number of unique customers per country in order to see if the same argument as presented here holds. Even if the numbers are wildly incorrect, we could still reuse this kind of reasoning to pinpoint potential markets for expansion.
